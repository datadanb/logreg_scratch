{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import getpass    # For users\n",
    "import h5py       # For data files input\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Setting up data input directory\n",
    "user = getpass.getuser()\n",
    "desktop_or_laptop = 'd' # 'l' # This is for Dan\n",
    "\n",
    "if user == 'scgst':\n",
    "    with h5py.File('images_training.h5','r') as H:\n",
    "        X_train = np.copy(H['data'])\n",
    "    with h5py.File('labels_training.h5','r') as H:\n",
    "        y_train = np.copy(H['label'])\n",
    "    with h5py.File('images_testing.h5','r') as H:\n",
    "        X_test = np.copy(H['data'])[range(2000), ]\n",
    "    with h5py.File('labels_testing_2000.h5','r') as H:\n",
    "        y_test = np.copy(H['label'])\n",
    "        \n",
    "# Transforming the feature inputs\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# # check\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# Normalisation on features\n",
    "from sklearn.preprocessing import normalize\n",
    "X_train = normalize(X_train.astype('float32'))\n",
    "X_test = normalize(X_test.astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use test set or validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "validate_switch = False\n",
    "\n",
    "if validate_switch:\n",
    "    # Split Train into train + validation\n",
    "    validate_percentage = 0.7\n",
    "    X_train_validate, X_validate, y_train_validate, y_validate = train_test_split(X_train, y_train, test_size = validate_percentage, random_state = 109)\n",
    "    \n",
    "    X_train = X_train_validate \n",
    "    y_train = y_train_validate\n",
    "    X_test = X_validate\n",
    "    y_test = y_validate\n",
    "\n",
    "# # check\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "# https://towardsdatascience.com/pca-using-python-scikit-learn-e653f8989e60\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "PCA_switch = True\n",
    "\n",
    "if PCA_switch:\n",
    "    component_nbr = 100\n",
    "    pca = PCA(n_components = component_nbr, svd_solver = 'randomized', whiten = True).fit(X_train)\n",
    "    X_train = pca.transform(X_train)\n",
    "    X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes - SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Method takes 0.11070466041564941 seconds\n",
      "Gaussian Naive Bayes Method's accuracy is 0.7575\n",
      "Gaussian Naive Bayes Method's confusion matrix:\n",
      "[[129   0   0  15   0  10  19   0   5   0]\n",
      " [  2 174   2   9   0   2   2   0   0   0]\n",
      " [  1   0 134   3  44  11  13   0   4   0]\n",
      " [  4   0   2 153  12  14   4   0   2   0]\n",
      " [  0   0  19  10 159  11  10   0   3   0]\n",
      " [  0   0   0   1   0 182   0  23   1   7]\n",
      " [ 34   0  19  10  53  16  62   0   6   0]\n",
      " [  0   0   0   0   0  23   0 159   0  16]\n",
      " [  0   0   3   2   2  11   4   1 196   0]\n",
      " [  0   0   0   0   0  12   0   6   2 167]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "start_0 = time.time()\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb_fit = gnb.fit(X_train, y_train)\n",
    "y_pred = gnb_fit.predict(X_test)\n",
    "\n",
    "end_0 = time.time()\n",
    "print(\"Gaussian Naive Bayes Method takes\", end_0 - start_0, \"seconds\")\n",
    "\n",
    "print(\"Gaussian Naive Bayes Method's accuracy is\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Gaussian Naive Bayes Method's confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM - SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Method takes 116.88875722885132 seconds\n",
      "SVM Method's accuracy is 0.877\n",
      "SVM Method's confusion matrix:\n",
      "[[149   0   4   4   0   1  19   0   1   0]\n",
      " [  0 187   0   4   0   0   0   0   0   0]\n",
      " [  2   0 178   1  15   1  13   0   0   0]\n",
      " [  4   1   1 169   6   4   6   0   0   0]\n",
      " [  0   1  22   9 159   0  21   0   0   0]\n",
      " [  0   0   0   0   0 208   0   2   0   4]\n",
      " [ 21   1  20   7  17   3 128   0   3   0]\n",
      " [  0   0   0   0   0   5   0 185   0   8]\n",
      " [  0   0   0   0   0   5   1   1 212   0]\n",
      " [  0   0   0   0   0   1   0   6   1 179]]\n"
     ]
    }
   ],
   "source": [
    "# SVM - SKlearn\n",
    "# https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "start_0 = time.time()\n",
    "\n",
    "# Classify 0\n",
    "svc = svm.SVC(kernel = 'rbf', C = 1E6, gamma = 'scale', decision_function_shape = 'ovo') #kernel could also be linear, etc..\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "end_0 = time.time()\n",
    "print(\"SVM Method takes\", end_0 - start_0, \"seconds\")\n",
    "\n",
    "print(\"SVM Method's accuracy is\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"SVM Method's confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression takes 3.2173678874969482 seconds\n",
      "Logistic Regression's accuracy is 0.8435\n",
      "Logistic Regression's confusion matrix:\n",
      "[[144   0   1  13   0   0  18   0   2   0]\n",
      " [  0 185   1   5   0   0   0   0   0   0]\n",
      " [  5   1 152   1  32   0  16   0   3   0]\n",
      " [  6   4   1 173   5   0   1   0   1   0]\n",
      " [  0   0  21   9 160   0  20   0   2   0]\n",
      " [  0   1   0   0   0 202   0   3   0   8]\n",
      " [ 34   0  25  10  32   0  96   0   3   0]\n",
      " [  0   0   0   0   0   6   0 187   0   5]\n",
      " [  1   1   1   2   0   2   4   2 206   0]\n",
      " [  0   0   0   0   0   1   0   3   1 182]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scgst\\Documents\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression - SKlearn\n",
    "# https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "start_0 = time.time()\n",
    "\n",
    "lgr = LogisticRegression(random_state = 0, solver = 'lbfgs', multi_class = 'multinomial')\n",
    "lgr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgr.predict(X_test)\n",
    "\n",
    "end_0 = time.time()\n",
    "print(\"Logistic Regression takes\", end_0 - start_0, \"seconds\")\n",
    "\n",
    "print(\"Logistic Regression's accuracy is\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Logistic Regression's confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN - SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression takes 25.109833240509033 seconds\n",
      "Logistic Regression's accuracy is 0.8195\n",
      "Logistic Regression's confusion matrix:\n",
      "[[164   1   1   1   2   0   6   0   3   0]\n",
      " [  1 185   0   3   1   0   1   0   0   0]\n",
      " [  4   0 161   0  29   0  15   0   1   0]\n",
      " [  8   2   2 168   8   0   2   0   1   0]\n",
      " [  0   0  18  10 171   0  13   0   0   0]\n",
      " [  1   0   0   0   1 121   0  37   3  51]\n",
      " [ 40   0  25   6  32   0  93   0   4   0]\n",
      " [  0   0   0   0   0   0   0 185   0  13]\n",
      " [  1   1   2   1   4   0   0   0 210   0]\n",
      " [  0   0   0   0   0   0   0   5   1 181]]\n"
     ]
    }
   ],
   "source": [
    "# KNN - SKlearn\n",
    "# https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "start_0 = time.time()\n",
    "\n",
    "KNN = KNeighborsClassifier(n_neighbors = 10)\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "y_pred = KNN.predict(X_test)\n",
    "\n",
    "end_0 = time.time()\n",
    "print(\"Logistic Regression takes\", end_0 - start_0, \"seconds\")\n",
    "\n",
    "print(\"Logistic Regression's accuracy is\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Logistic Regression's confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
