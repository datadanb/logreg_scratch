{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions and general imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as scpy\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from scipy import optimize as opt\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining utility functions for reading images and data in\n",
    "def show_image(array, label):\n",
    "    im = Image.fromarray(array)\n",
    "    print(\"Item of label={}\".format(label))\n",
    "    return(imshow(im))\n",
    "\n",
    "def construct_conf_mat(actual_y, predicted_prob, pos_class_label, thresh=0.5):\n",
    "    fp, tp, fn, tn = 0, 0, 0, 0\n",
    "    for i in range(actual_y.shape[0]):\n",
    "        if predicted_prob[i] >= thresh:\n",
    "            if actual_y[i] == pos_class_label:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if actual_y[i] == pos_class_label:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    return fp, tp, fn, tn\n",
    "    \n",
    "    \n",
    "def compress_project(percent, data_to_compress):\n",
    "\n",
    "# Find the principal components that explain 99% of the data\n",
    "    pca = decomposition.PCA(percent)\n",
    "\n",
    "    #Run PCA on normalized image data\n",
    "    lower_dim_data = pca.fit_transform(data_to_compress)    \n",
    "    print('Shape of lower dimension image {}:'.format(lower_dim_data.shape))\n",
    "\n",
    "    #Project lower dimension data onto original features\n",
    "    approximation = pca.inverse_transform(lower_dim_data)\n",
    "    #approximation = pca.inverse_transform(lower_dim_data)\n",
    "        \n",
    "    #Reshape approximation and X_norm to 784*28*28 to display images\n",
    "    approximation_reshaped = approximation.reshape(-1,784)\n",
    "    print('Shape of reconstructed image {}:'.format(approximation_reshaped.shape))   \n",
    "    print( 'Is Original close to Resized? ', np.allclose(data_to_compress, approximation) )\n",
    "    \n",
    "    return (approximation, lower_dim_data) \n",
    "\n",
    "\n",
    "def shape_matrix_process(split_percent):\n",
    "    \n",
    "            \n",
    "        # Read the source files in\n",
    "        data, label, test_data, test_label = read_data_in(desktop_or_laptop='d')\n",
    "\n",
    "        # Creating a fair split of training and validation data for the \n",
    "        # training model to be trained on\n",
    "        indices = range(data.shape[0])\n",
    "        classes = np.unique(label)\n",
    "        \n",
    "        training_records = int(split_percent * data.shape[0])        \n",
    "        \n",
    "        # Get the records that are part of the indices declared above\n",
    "        train_data = data[:training_records]\n",
    "        validate_data = data[training_records:]        \n",
    "        \n",
    "        # Get the labels that are part of the indices declared above\n",
    "        label_train = label[:training_records]\n",
    "        label_validate = label[training_records:]        \n",
    "        \n",
    "        \n",
    "        get_class_data = np.vectorize(lambda arr: label==i )\n",
    "                \n",
    "        \n",
    "        for i in classes:\n",
    "            print(\"Pixel histogram prior to feature scaling : \".format(classes[i]))\n",
    "            print(i)\n",
    "        \n",
    "            d=[]\n",
    "            d = data[get_class_data(i)]\n",
    "            h = plt.hist(d[i].ravel())\n",
    "            plt.show()\n",
    "\n",
    "        X_train = train_data.reshape(-1, 784)\n",
    "        X_validate = validate_data.reshape(-1, 784)\n",
    "        #X_scaled_data = data.reshape(-1,784)\n",
    "        X_train.shape\n",
    "        \n",
    "        y_train = np.ravel(label_train)\n",
    "        y_validate = np.ravel(label_validate)    \n",
    "\n",
    "                \n",
    "        ##########################################################################  \n",
    "        # MINMAXSCALER IS THE ONLY SCALER FOUND TO RELIABLY RESULT IN CONVERGENCE*\n",
    "        # HOWEVER NEEDS FURTHER TESTING =========================================#\n",
    "        ##########################################################################\n",
    "\n",
    "        #X_train = preprocessing.scale(X_train)\n",
    "        #min_max_scaler = MinMaxScaler()\n",
    "        # Fit & transform to our training data set\n",
    "        X_train = X_train.astype('float32')\n",
    "        #X_train = min_max_scaler.fit_transform(X_train,y_train)\n",
    "        X_train = normalise(X_train)\n",
    "        \n",
    "        \n",
    "        # Change our X_Validate data set to float 32 to \n",
    "        \n",
    "        X_validate = X_validate.astype('float32')\n",
    "        X_validate = normalise(X_validate)\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        # How does the 'data' array look post feature scaling?\n",
    "        \n",
    "        #for i in classes:\n",
    "        #    print(\"Pixel histogram post to feature scaling : \".format(classes[i]))\n",
    "        #    print(i)\n",
    "        # \n",
    "        #    d=[]\n",
    "        #    d = X_scaled_data[get_class_data(i)]\n",
    "        #    h = plt.hist(d[i].ravel())\n",
    "        #    plt.show()\n",
    "        \n",
    "        \n",
    "        print('Total number of records in X train: {}'.format(X_train.shape[0]))\n",
    "        print('Total number of records in y train: {}'.format(y_train.shape[0]))\n",
    "        print('Total number of features in X train: {}'.format(X_train.shape[1]))\n",
    "\n",
    "        print('Total number of records in X train (valdation set): {}'.format(X_validate.shape[0]))\n",
    "        print('Total number of features in X train (validation set): {}'.format(X_validate.shape[1]))\n",
    "        \n",
    "       \n",
    "        ########################\n",
    "        # Now to transform test#\n",
    "        ########################\n",
    "        \n",
    "        X_test = test_data[:2000]        \n",
    "        X_test = test_data.reshape(-1,784)\n",
    "        y_test = test_label [:2000]       \n",
    "        X_test = X_test.astype('float32')\n",
    "            \n",
    "        ##########################################################################  \n",
    "        # MINMAXSCALER IS THE ONLY SCALER FOUND TO RELIABLY RESULT IN CONVERGENCE*\n",
    "        # HOWEVER NEEDS FURTHER TESTING =========================================#\n",
    "        ##########################################################################\n",
    "\n",
    "   \n",
    "        X_test = normalise(X_test)\n",
    "                                          \n",
    "        print('Total number of records in X test: {}'.format(X_test.shape[0]))\n",
    "        print('Total number of features in X test: {}'.format(X_test.shape[1]))\n",
    "        \n",
    "        return(X_train,X_validate,X_test,y_train,y_validate,y_test)\n",
    "    \n",
    "    \n",
    "# Import the files in from python h5 format\n",
    "\n",
    "\n",
    "def read_data_in(desktop_or_laptop='d'):\n",
    "    \n",
    "    if desktop_or_laptop == 'l':\n",
    "\n",
    "        ## Dan's Mac folder location - NEEDS CHANGING\n",
    "        with h5py.File('../Project1/data/images_training.h5','r') as H:\n",
    "            data = np.copy(H['data'])\n",
    "        with h5py.File('../Project1/data/labels_training.h5','r') as H:\n",
    "            label = np.copy(H['label'])\n",
    "\n",
    "        with h5py.File('../Project1/data/images_testing.h5','r') as H:\n",
    "            data_test = np.copy(H['data'])\n",
    "        with h5py.File('../Project1/data/labels_testing_2000.h5','r') as H:\n",
    "            label_test = np.copy(H['label'])    \n",
    "\n",
    "\n",
    "    else:\n",
    "        ## Dan's desktop folder location - NEEDS CHANGING\n",
    "        with h5py.File('../../Input/images_training.h5','r') as H:\n",
    "            data = np.copy(H['data'])\n",
    "        with h5py.File('../../Input/labels_training.h5','r') as H:\n",
    "            label = np.copy(H['label'])\n",
    "        with h5py.File('../../Input/images_testing.h5','r') as H:\n",
    "            data_test = np.copy(H['data'])\n",
    "\n",
    "        with h5py.File('../../Input/labels_testing_2000.h5','r') as H:\n",
    "            label_test = np.copy(H['label'])     \n",
    "    \n",
    "    return(data, label, data_test, label_test)\n",
    "\n",
    "def add_intercept(X_mat,y_mat):\n",
    "    m = len(y_mat)\n",
    "    ones = np.ones((m,1))\n",
    "    \n",
    "    X = np.concatenate((ones,X_mat),axis=1)\n",
    "    m,n = X.shape\n",
    "    print(X.shape)\n",
    "    return(X,n)\n",
    "\n",
    "# Is the matrix symmetric?\n",
    "def is_symmetric(X, tolerance = 1e-9):\n",
    "    return(np.allclose(X,X.T, atol=tolerance))\n",
    "\n",
    "def get_minmax(X):\n",
    "    minmax = list()\n",
    "    for i in range(len(X[0])):\n",
    "        column_values = [row[i] for row in X]\n",
    "        mn = min(column_values)\n",
    "        mx = max(column_values)\n",
    "        minmax.append([mn,mx])\n",
    "    return(minmax)\n",
    "\n",
    "def normalise(X):\n",
    "    #print(X_train.shape)\n",
    "    X_scaled = (X - np.min(X,axis=0)) / (np.max(X, axis=0) - (np.min(X,axis=0) ))\n",
    "    return(X_scaled)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self,  max_iter, intercept, k, lmbda ):\n",
    "        #self.lr = lr\n",
    "        self.max_iter = max_iter\n",
    "        self.intercept = intercept\n",
    "        self.k = k\n",
    "        self.lmbda = lmbda\n",
    "        print (\"Logistic Regression model initialised with Max iterations = {}, K (classes) = {}, lmbda (Regularisation parameter) ={}\".format(self.max_iter,self.k, self.lmbda))\n",
    "    \n",
    "    def add_intercept(self, X_mat,y_mat):\n",
    "        m = len(y_mat)\n",
    "        ones = np.ones((m,1))\n",
    "\n",
    "        X_mat = np.concatenate((ones,X_mat),axis=1)\n",
    "        m_shape,n_shape = X_mat.shape\n",
    "        #print(\"n_shape: {}\".format(n_shape))\n",
    "        #print(\"X_mat.shape: {}\".format(X_mat.shape))\n",
    "        \n",
    "        return(X_mat,n_shape)\n",
    "    \n",
    "    # Defining the sigmoid function required in LR\n",
    "    def __sigmoid(self, z):\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def __cost(self, theta, X_arr, y_arr):\n",
    "        predictions = self.__sigmoid(X_arr @ theta)\n",
    "        predictions[predictions == 1] = 0.999 # log(1)=0 causes error in division\n",
    "        error = -y_arr * np.log(predictions) - (1 - y_arr) * np.log(1 - predictions);\n",
    "        return sum(error) / len(y_arr);\n",
    "    \n",
    "    # Vectorised cost function\n",
    "    def __costFunctionReg(self,theta, X, y, lmbda):\n",
    "        m = len(y)\n",
    "        temp1 = np.multiply(y, np.log(self.__sigmoid(np.dot(X, theta))))\n",
    "        temp2 = np.multiply(1-y, np.log(1-self.__sigmoid(np.dot(X, theta))))  \n",
    "        #print(np.sum(temp1 + temp2) / (-m) + np.sum(theta[1:]**2) * lmbda / (2*m))\n",
    "        return np.sum(temp1 + temp2) / (-m) + np.sum(theta[1:]**2) * lmbda / (2*m)\n",
    "    \n",
    "    \n",
    "    def fit(self, X_mat,max_iter, y_mat,n, full_outp):\n",
    "                        \n",
    "        theta = np.zeros((k,n)) #inital parameters\n",
    "        cost_values = {}\n",
    "        \n",
    "        \n",
    "        print(\"                                            \")\n",
    "        print(\"############################################\")\n",
    "        print(\"### Gradient Descent Optimisation beginning\")\n",
    "        print(\"############################################\")\n",
    "        for i in range(k):\n",
    "            label_class = i if i else 0\n",
    "            print('Class {} being optimised'.format(i))\n",
    "            #cost0 = cost(theta, X, (y==label_class.flatten()))\n",
    "            #cost[i] = cost(theta[i], X,y)\n",
    "            #print('Cost for Class {}:'.format(cost[i]))               \n",
    "            #ValueError: cannot copy sequence with size 5 to array axis with dimension 785\n",
    "            theta[i] = opt.fmin_cg(f = self.__costFunctionReg, x0 = theta[i].flatten(), gtol = 1e-03, fprime = self.__gradient_reg_vectorised, args = (X_mat,(y_mat == label_class).flatten(), self.lmbda),maxiter= max_iter, disp = True, full_output = full_outp)                        \n",
    "            #cost = {i,}\n",
    "            #theta[i] = opt.fmin_cg(f = costFunctionReg, x0 = theta[i].flatten(),  fprime = gradRegularization, args = (X_mat,(y == label_class).flatten(), lmbda), maxiter = 200, disp = True)    \n",
    "            \n",
    "        print(\"###########################################\")\n",
    "        print(\"### Gradient Descent Optimisation finished\")\n",
    "        print(\"###########################################\")\n",
    "            #if full_outp == 1:\n",
    "            #    return(theta, fopt, func_calls, grad_calls, warnflag)\n",
    "            #else:\n",
    "            #    return(theta)\n",
    "        return(theta)\n",
    "    \n",
    "      \n",
    "    \n",
    "    # Vectorised gradient\n",
    "    def __gradient_reg_vectorised(self, theta, X_arr, y_arr, lmbda):\n",
    "        m = len(y_arr)\n",
    "        temp = self.__sigmoid(np.dot(X_arr, theta)) - y_arr\n",
    "        temp = np.dot(temp.T, X_arr).T / m + theta * lmbda / m\n",
    "        temp[0] = temp[0] - theta[0] * lmbda / m\n",
    "        return temp\n",
    "    \n",
    "    # Vectorised cost function\n",
    "    def __cost_func_vectorised(self,theta, X_arr, y_arr, lmbda):\n",
    "        m = len(y_arr)\n",
    "        temp_weight1 = np.multiply(y_arr, np.log(self.__sigmoid(np.dot(X_arr, theta))))\n",
    "        temp_weight2 = np.multiply(1-y_arr, np.log(1-self.__sigmoid(np.dot(X_arr, theta))))\n",
    "        return np.sum(temp_weight1 + temp_weight2) / (-m) + np.sum(theta[1:]**2) * self.lmbda / (2*m)\n",
    "    \n",
    "    \n",
    "    def predict(self,X,y,theta):    \n",
    "        preds = []\n",
    "        preds = np.argmax(X @ theta.T, axis = 1)\n",
    "        preds = [e if e else 0 for e in preds]\n",
    "        average_pred = np.mean(preds == y.flatten()) * 100        \n",
    "        return(preds, average_pred)\n",
    "        #return(average_pred)\n",
    "    \n",
    "    def predict_prob(self,X, theta):\n",
    "        return (self.__sigmoid(np.dot(X),theta.T))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For reference: https://github.com/zalandoresearch/fashion-mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Label | Description   |\n",
    "|------|------|\n",
    "|   0  | T-shirt/top|\n",
    "|   1  | Trouser|\n",
    "|   2  | Pullover|\n",
    "|   3  | Dress|\n",
    "|   4  | Coat|\n",
    "|   5  | Sandal|\n",
    "|   6  | Shirt|\n",
    "|   7  | Sneaker|\n",
    "|   8  | Bag|\n",
    "|   9  | Ankle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data, label, data_test, label_test = read_data_in(desktop_or_laptop='d')\n",
    "\n",
    "train_data = data[:30000]\n",
    "\n",
    "X_train = train_data.reshape(-1, 784)\n",
    "\n",
    "\n",
    "#def is_symmetric(X, tolerance = 1e-9):\n",
    "#    return(np.allclose(X,X.T, atol=tolerance))\n",
    "\n",
    "\n",
    " #= data.reshape[-1,784]\n",
    "#is_sparse(X_train,X_train.shape[0],X_train.shape[1])\n",
    "#X.shape\n",
    "#scpy.sparse.isspmatrix(train_data)\n",
    "\n",
    "#X_train.shape\n",
    "#data.reshape[-1,784]\n",
    "#data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating histograms for all classes to see pixel distributions\n",
    "#bin_counts, no_of_bins = np.histogram(data,10)\n",
    "\n",
    "#plt.hist(x = data.ravel(), bins = no_of_bins)\n",
    "\n",
    "\n",
    "get_class_data = np.vectorize(lambda arr: label==i )\n",
    "\n",
    "for i in classes:\n",
    "    #print(\"Pixel histogram for label : \".format(classes[i]))\n",
    "    print(i)\n",
    "    \n",
    "    d=[]\n",
    "    d = data[get_class_data(i)]\n",
    "    h = plt.hist(d[i].ravel())\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train,X_validate,X_test,y_train,y_validate,y_test = shape_matrix_process(split_percent=0.9)\n",
    "\n",
    "#get_class_data = np.vectorize(lambda arr: label==i )\n",
    "\n",
    "#for i in classes:\n",
    "    #print(\"Pixel histogram for label : \".format(classes[i]))\n",
    "    #print(i)\n",
    "    \n",
    "#    d=[]\n",
    "#    d = X_train[get_class_data(i)]\n",
    "#    h = plt.hist(d[i].ravel())\n",
    "#    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "#show_image(data[i],label[i])\n",
    "\n",
    "#print('Total training data shape : ', data.shape, label.shape)\n",
    "#data_train = data_train / 255\n",
    "\n",
    "\n",
    "_, axarr = plt.subplots(10,10,figsize=(10,10))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "       data[np.random.randint(data.shape[0])] \n",
    "       axarr[i,j].axis('off')     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many unique classes are we dealing with? Do we need to perform any sampling for class imbalance?\n",
    "classes = np.unique(label)\n",
    "nclasses = len(classes)\n",
    "test_classes = np.unique(label_test)\n",
    "test_nclasses = len(test_classes)\n",
    "\n",
    "\n",
    "print('Total number of classes in Train: ', nclasses)\n",
    "print('Total number of classes in Test : ', test_nclasses)\n",
    "print('Classes to classify in Train are : ', classes)\n",
    "print('Classes to classify in Test are : ', test_classes)\n",
    "\n",
    "\n",
    "unique, counts = np.unique(label, return_counts=True)\n",
    "print('Distribution of labels against total population in Train:')\n",
    "dict(zip(unique,counts))\n",
    "\n",
    "unique_test, count_test = np.unique(label_test, return_counts=True)\n",
    "print('Distribution of labels against total population in Test:')\n",
    "dict(zip(unique_test,count_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up terms, intercept and gradients for LogisticRegression - OVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3beb550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde2f6a908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1JzBr0kNWfQS1Jz/wNAAy/tpNWwwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3051400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSY0z6CWpcQa9JDXOoJekxv0vF6uhQJ+NCEUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde2f6acf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde30c62e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde2dc9358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3a1e908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3d82358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL0nNGfSS1Nz/AEK1MvH/2rAQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3c019e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel histogram prior to feature scaling : \n",
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dde3a7f780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\New\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:208: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records in X train: 29700\n",
      "Total number of records in y train: 29700\n",
      "Total number of features in X train: 784\n",
      "Total number of records in X train (valdation set): 300\n",
      "Total number of features in X train (validation set): 784\n",
      "Total number of records in X test: 5000\n",
      "Total number of features in X test: 784\n",
      "#################################################\n",
      "Logistic Regression model initialised with Max iterations = 500, K (classes) = 10, lmbda (Regularisation parameter) =2\n",
      "#################################################\n",
      "                                            \n",
      "############################################\n",
      "### Gradient Descent Optimisation beginning\n",
      "############################################\n",
      "Class 0 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.098526\n",
      "         Iterations: 42\n",
      "         Function evaluations: 86\n",
      "         Gradient evaluations: 86\n",
      "Class 1 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.023542\n",
      "         Iterations: 16\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n",
      "Class 2 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.135668\n",
      "         Iterations: 41\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 91\n",
      "Class 3 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.086755\n",
      "         Iterations: 27\n",
      "         Function evaluations: 50\n",
      "         Gradient evaluations: 50\n",
      "Class 4 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.120571\n",
      "         Iterations: 43\n",
      "         Function evaluations: 100\n",
      "         Gradient evaluations: 100\n",
      "Class 5 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.049141\n",
      "         Iterations: 24\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "Class 6 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176684\n",
      "         Iterations: 44\n",
      "         Function evaluations: 81\n",
      "         Gradient evaluations: 81\n",
      "Class 7 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.050777\n",
      "         Iterations: 20\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 42\n",
      "Class 8 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.046376\n",
      "         Iterations: 34\n",
      "         Function evaluations: 69\n",
      "         Gradient evaluations: 69\n",
      "Class 9 being optimised\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.035441\n",
      "         Iterations: 38\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 75\n",
      "###########################################\n",
      "### Gradient Descent Optimisation finished\n",
      "###########################################\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loop_count = 1\n",
    "\n",
    "prediction_average_test = []\n",
    "\n",
    "for i in range(loop_count):\n",
    "\n",
    "    # Read the source files in\n",
    "    data, label, data_test, label_test = read_data_in(desktop_or_laptop='d')\n",
    "\n",
    "    # Declare variables for instantiation of the LogisticRegression Class\n",
    "    lmbda = 2\n",
    "    k = 10\n",
    "    intercept = True\n",
    "    max_iter = 500\n",
    "\n",
    "    #n = []\n",
    "    # THIS IS A HACK, NOT SURE WHY TEST DATA ISN'T BEING READ IN PROPERLY CURRENTLY\n",
    "    data_test = data_test[:2000]\n",
    "\n",
    "    #########################################################################################\n",
    "    # Once data is read in from file data, we split it for training, validation and testing #\n",
    "    # standardise, & re-shape it process                                                    #\n",
    "    #########################################################################################\n",
    "        \n",
    "    X_train,X_validate,X_test,y_train,y_validate,y_test = shape_matrix_process(split_percent=0.99)\n",
    "    X_test = X_test[:2000]\n",
    "\n",
    "\n",
    "    ############################################\n",
    "    # Instantiate our logistic Regression model#\n",
    "    ############################################\n",
    "    print('#################################################')\n",
    "    model = LogisticRegression(max_iter, intercept, k, lmbda)\n",
    "    print('#################################################')\n",
    "\n",
    "    # Carry out principal component analysis and project back with 99% of variance\n",
    "    #X_train, X_reduced  = compress_project(percent=.99,data_to_compress=X_train)\n",
    "\n",
    "    # Add the intercept value\n",
    "    X_train,n = model.add_intercept(X_train,y_train)\n",
    "\n",
    "    # Create a theta matrix to capture values of theta when we minimis the objective function below\n",
    "    theta = np.zeros((k,n)) #inital parameters\n",
    "\n",
    "    #############################################################################################\n",
    "    # Using conjugate gradient, we attempt to carry out optimisation to find theta and therefore#\n",
    "    # Using theta and the data features to predict each class   #################################\n",
    "    #############################################################################################\n",
    "    \n",
    "    # Do you want to see a verbose/full output for conjugate gradient descent?\n",
    "    \n",
    "    #theta = model.fit(X_mat=X_train,max_iter=500,y_mat=y_train,n=n, full_outp=False)\n",
    "    \n",
    "    \n",
    "    #theta, fopt, func_calls, grad_calls,warnflag  = model.fit(X_mat=X_train,max_iter=500,y_mat=y_train,n=n, full_outp=False)\n",
    "    theta  = model.fit(X_mat=X_train,max_iter=500,y_mat=y_train,n=n, full_outp=False)\n",
    "        \n",
    "    \n",
    "    #######################################################################################\n",
    "    # Carry out the predictions based on the trained model and then carry out predictions #\n",
    "    # on the unseen test data                                                             #\n",
    "    #######################################################################################\n",
    "    X_test,n = model.add_intercept(X_test,y_test)\n",
    "\n",
    "    #prediction_average_test.append(model.predict(X_test,y_test,theta=theta))\n",
    "    #prediction_average_test.append(model.predict(X_test,y_test,theta=theta))\n",
    "    #prediction_average_test\n",
    "\n",
    "# With feature scaling (min/max) - Convergence of all classes\n",
    "# Wall time: 2min 6s\n",
    "\n",
    "#CPU times: user 4min 13s, sys: 2.81 s, total: 4min 16s\n",
    "#Wall time: 2min 14s\n",
    "\n",
    "# CPU times: user 4min 22s, sys: 1.55 s, total: 4min 24s\n",
    "# Wall time: 2min 15s\n",
    "\n",
    "\n",
    "# 5 time loop of \n",
    "# CPU times: user 21min 56s, sys: 9.06 s, total: 22min 5s\n",
    "# Wall time: 11min 22s\n",
    "\n",
    "# CPU times: user 22min 5s, sys: 10.4 s, total: 22min 15s\n",
    "# Wall time: 11min 35s\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# Without feature scaling - Convergence of all classes\n",
    "# CPU times: user 9min 29s, sys: 5.33 s, total: 9min 35s\n",
    "# Wall time: 5min 3s\n",
    "\n",
    "# CPU times: user 9min 8s, sys: 2.48 s, total: 9min 10s\n",
    "# Wall time: 4min 47s\n",
    "\n",
    "# CPU times: user 9min 17s, sys: 2.7 s, total: 9min 20s\n",
    "# Wall time: 4min 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.6026936026936"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "84.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction_average = []\n",
    "preds, prediction_average = model.predict(X=X_train,y=y_train,theta=theta)\n",
    "prediction_average\n",
    "\n",
    "#X_test,n = model.add_intercept(X_test,y_test)\n",
    "prediction_average_test = []\n",
    "#prediction_average_test = model.predict(X_test,y_test,theta=theta)\n",
    "preds_test,prediction_average_test   = model.predict(X_test,y_test,theta=theta)\n",
    "prediction_average_test\n",
    "#preds_test\n",
    "\n",
    "\n",
    "#87.68771929824561\n",
    "# 84.0\n",
    "\n",
    "#87.51578947368421\n",
    "#84.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the optimal weights and parameters for the 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 6, ..., 5, 2, 9], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lmbda = 5\n",
    "k = 10\n",
    "max_iter = 275\n",
    "\n",
    "\n",
    "#X=data_test\n",
    "#y=label_test\n",
    "#train_or_test='test'\n",
    "\n",
    "#X_test,y_test = shape_matrix_process(X_test, y_test, train_or_test, split_percent)\n",
    "#X_test, n_train = add_intercept(X_test,y_test)\n",
    "\n",
    "theta = np.zeros((k,n)) #inital parameters\n",
    "\n",
    "# Time execution of the gradient descent and cost calculations\n",
    "%timeit -n 1 -r 1 theta = create_multiclass_c(X_mat=X_train, max_iter=max_iter, y_mat=y_train,n=n)\n",
    "#%timeit -n 1 -r 1 theta = create_multiclass_c(X_validate,n, max_iter, y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test,n = add_intercept(X_test,y_test)\n",
    "\n",
    "pred = []\n",
    "pred = np.argmax(X_test @ theta.T, axis = 1)\n",
    "pred = [e if e else 0 for e in pred]\n",
    "np.mean(pred == y_train.flatten()) * 100\n",
    "\n",
    "#79.74166666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "preds = np.argmax(X_train @ theta.T, axis = 1)\n",
    "preds = [e if e else 0 for e in pred]\n",
    "np.mean(preds ==y_train.flatten()) * 100\n",
    "#79.74166666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_test[0:10]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_validate = []\n",
    "pred_validate = np.argmax(X_validate @ theta.T, axis = 1)\n",
    "pred = [e if e else 0 for e in pred]\n",
    "pred_accuracies = pred_validate == y_validate.flatten()\n",
    "np.mean(pred_validate ==y_validate.flatten()) * 100\n",
    "#79.74166666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_train = []\n",
    "pred_train = np.argmax(X_train @ theta.T, axis = 1)\n",
    "pred = [e if e else 0 for e in pred_train]\n",
    "np.mean(pred_train == y_train.flatten()) * 100\n",
    "\n",
    "pred_test = []\n",
    "pred_test = np.argmax(X_test @ theta.T, axis = 1)\n",
    "pred = [e if e else 0 for e in pred_test]\n",
    "np.mean(pred_test == y_test.flatten()) * 100\n",
    "\n",
    "#79.74166666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(pred_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, preds_test)\n",
    "#cm = metrics.confusion_matrix(y_train, preds)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(prediction_average_test)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[2], tpr[2], color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gaussian Naive Bayes as alternate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Trying with train\n",
    "gnb = GaussianNB().fit(X,y)\n",
    "gnb_pred = gnb.predict(X_validate)\n",
    "\n",
    "gnb_accuracy = gnb.score(X_validate,y_validate)\n",
    "print(gnb_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
