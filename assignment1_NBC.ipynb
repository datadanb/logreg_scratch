{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import getpass # For users\n",
    "import h5py    # For data files input\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up data input directory\n",
    "user = getpass.getuser()\n",
    "desktop_or_laptop = 'd' # 'l' # This is for Dan\n",
    "\n",
    "if user == 'scgst':\n",
    "    with h5py.File('images_training.h5','r') as H:\n",
    "        X_train_raw = np.copy(H['data'])\n",
    "    with h5py.File('labels_training.h5','r') as H:\n",
    "        y_train_raw = np.copy(H['label'])\n",
    "    with h5py.File('images_testing.h5','r') as H:\n",
    "        X_test_raw = np.copy(H['data'])\n",
    "    with h5py.File('labels_testing_2000.h5','r') as H:\n",
    "        y_test_raw = np.copy(H['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the feature inputs\n",
    "X_train_reshape = X_train_raw.reshape(-1, 784)\n",
    "X_test_reshape = X_test_raw.reshape(-1, 784)\n",
    "\n",
    "# # check\n",
    "# print(X_train_reshape.shape)\n",
    "# print(X_test_reshape.shape)\n",
    "# print(y_train_raw.shape)\n",
    "# print(y_test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalisation on features\n",
    "# from sklearn.preprocessing import normalize\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_train = normalize(X_train)\n",
    "\n",
    "# X_test = X_test.astype('float32')\n",
    "# X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train into train + validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "validate_percentage = 0.3\n",
    "X_train_post_validate, X_validate, y_train_post_validate, y_validate = train_test_split(X_train_reshape, y_train_raw, test_size = test_percentage, random_state = 109)\n",
    "\n",
    "# # check\n",
    "# print(X_train.shape)\n",
    "# print(X_validate.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_validate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "component_nbr = 100\n",
    "\n",
    "pca = PCA(n_components = component_nbr, svd_solver = 'randomized', whiten = True).fit(X_train_post_validate)\n",
    "\n",
    "X_train_pca = pca.transform(X_train_post_validate)\n",
    "X_validate_pca = pca.transform(X_validate)\n",
    "X_test_pca = pca.transform(X_test_reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align with array names\n",
    "X_train = X_train_pca\n",
    "X_validate = X_validate_pca\n",
    "X_test = X_test_pca\n",
    "y_train = y_train\n",
    "y_validate = y_validate\n",
    "y_test = y_test_raw\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_validate.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_validate.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes - Homemade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data by class\n",
    "import numpy as np\n",
    "def split_by_class(x, y, target_class):\n",
    "    pos_of_class = np.where(y == target_class)[0]\n",
    "    x_class = x[pos_of_class]\n",
    "    return x_class\n",
    "\n",
    "# # Check\n",
    "# sum_list = 0\n",
    "# for i in range(0, 10, 1):\n",
    "#     print(\"------\", i)\n",
    "#     a = split_by_class(X_train, y_train, i).shape[0]\n",
    "#     sum_list = sum_list + a\n",
    "#     print(sum_list)\n",
    "# \n",
    "# print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation for attributes by class\n",
    "def attribute_mean_std_by_class(x, y, target_class):\n",
    "    x_by_class = split_by_class(x, y, target_class)\n",
    "    attribute_mean = np.mean(x_by_class, axis = 0)\n",
    "    attribute_std = np.std(x_by_class, axis = 0)\n",
    "    return attribute_mean, attribute_std\n",
    "\n",
    "# # Check\n",
    "# mean, std = attribute_mean_std_by_class(X_train, y_train, 0)\n",
    "# print(mean.shape)\n",
    "# print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_prob(y, target_class):\n",
    "    class_count = list(y).count(target_class)\n",
    "    prob = class_count/len(y)\n",
    "    return prob\n",
    "\n",
    "# # Check\n",
    "# prob_list = 0\n",
    "# for i in range(0, 10, 1):\n",
    "#     print(\"------\", i)\n",
    "#     a = cal_class_prob(y_train, i)\n",
    "#     prob_list = prob_list + a\n",
    "#     print(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.074763483624114e-64\n",
      "2.7295459881324038e-80\n",
      "5.937413013289599e-59\n",
      "1.0786571440076576e-69\n",
      "1.9691722288271415e-62\n",
      "1.0339771286029378e-71\n",
      "3.7860511772261355e-61\n",
      "5.3128135235363345e-89\n",
      "8.424851945934824e-66\n",
      "1.7910866827428203e-70\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# for i in range(len(X_train)):\n",
    "#     X = X_train[i]\n",
    "\n",
    "i = 0\n",
    "X = X_train[i]\n",
    "\n",
    "for target_class in range(0, 10, 1):\n",
    "    mean, std = attribute_mean_std_by_class(X_train, y_train, target_class)\n",
    "    \n",
    "    exponent = np.exp(-np.power(X-mean, 2)/(2*np.power(std, 2)))\n",
    "    prob = exponent/(std*np.sqrt(2*math.pi))\n",
    "    prod_prob = np.nanprod(prob)\n",
    "    print(prod_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes - SKlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 8 ... 1 8 5]\n",
      "[[207   0   7  22   1   0  23   0  18   0]\n",
      " [  2 305   3  15   0   0   5   0   6   0]\n",
      " [  2   0 217   2  38   5  35   0  19   0]\n",
      " [ 20   2   4 238   3   3  20   0   9   0]\n",
      " [  4   0  39  12 194   1  44   0  16   0]\n",
      " [  1   0   0   0   0 219   8  60  15   6]\n",
      " [ 48   1  31   6  18   3 149   0  34   0]\n",
      " [  0   0   0   0   0  13   2 262   0  17]\n",
      " [  8   0   2   2   2   7  12   7 248   0]\n",
      " [  1   0   0   0   0   4   2  19   3 249]]\n",
      "0.7626666666666667\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "# Advantages v.s. Disadvantages https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn\n",
    "# Pros v.s. Cons https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/\n",
    "# https://blog.sicara.com/naive-bayes-classifier-sklearn-python-example-tips-42d100429e44\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_validate.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_validate.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb_fit = gnb.fit(X_train, y_train)\n",
    "y_pred = gnb_fit.predict(X_validate)\n",
    "\n",
    "print(gnb_pred)\n",
    "print(metrics.confusion_matrix(y_validate, y_pred))\n",
    "print(metrics.accuracy_score(y_validate, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
